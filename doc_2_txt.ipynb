{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx in /home/axat/myenv/lib/python3.11/site-packages (0.2.4)\n",
      "Requirement already satisfied: lxml in /home/axat/myenv/lib/python3.11/site-packages (from docx) (4.9.3)\n",
      "Requirement already satisfied: Pillow>=2.0 in /home/axat/myenv/lib/python3.11/site-packages (from docx) (10.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.table import Table\n",
    "from docx.text.paragraph import Paragraph\n",
    "\n",
    "\n",
    "def read_docx_objects(file_path, output_file_path):\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "        doc = Document(file_path)\n",
    "\n",
    "        # Process headers only once\n",
    "        processed_headers = set()\n",
    "        for section in doc.sections:\n",
    "            for header in section.header.paragraphs:\n",
    "                if header.text not in processed_headers:\n",
    "                    output_file.write(f'Header: {header.text}\\n')\n",
    "                    processed_headers.add(header.text)\n",
    "\n",
    "        # Process the main content of the document\n",
    "        for element in iter_elements(doc):\n",
    "            if isinstance(element, Paragraph):\n",
    "                output_file.write(f'{element.text}\\n')  # Separate paragraphs with a new line\n",
    "            elif isinstance(element, Table):\n",
    "                for row in element.rows:\n",
    "                    row_text = ' '.join([cell.text.replace('\\n', ' ') for cell in row.cells])\n",
    "                    output_file.write(f'{row_text}\\n')  # Separate cells with a space\n",
    "\n",
    "        # Process footers only once\n",
    "        processed_footers = set()\n",
    "        for section in doc.sections:\n",
    "            for footer in section.footer.paragraphs:\n",
    "                if footer.text not in processed_footers:\n",
    "                    output_file.write(f'Footer: {footer.text}\\n')\n",
    "                    processed_footers.add(footer.text)\n",
    "\n",
    "\n",
    "\n",
    "def iter_elements(doc):\n",
    "    elements_list = []\n",
    "    for element in doc.iter_inner_content():\n",
    "        elements_list.append(element)\n",
    "\n",
    "    return elements_list\n",
    "\n",
    "\n",
    "# Specify the output file path\n",
    "output_file_path = ''\n",
    "input_file_path = ''\n",
    "\n",
    "# Use the function with your docx file\n",
    "read_docx_objects(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum \n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc ac faucibus odio. \n",
      "\n",
      "Vestibulum neque massa, scelerisque sit amet ligula eu, congue molestie mi. Praesent ut varius sem. Nullam at porttitor arcu, nec lacinia nisi. Ut ac dolor vitae odio interdum condimentum. Vivamus dapibus sodales ex, vitae malesuada ipsum cursus convallis. Maecenas sed egestas nulla, ac condimentum orci. Mauris diam felis, vulputate ac suscipit et, iaculis non est. Curabitur semper arcu ac ligula semper, nec luctus nisl blandit. Integer lacinia ante ac libero lobortis imperdiet. Nullam mollis convallis ipsum, ac accumsan nunc vehicula vitae. Nulla eget justo in felis tristique fringilla. Morbi sit amet tortor quis risus auctor condimentum. Morbi in ullamcorper elit. Nulla iaculis tellus sit amet mauris tempus fringilla.\n",
      "Maecenas mauris lectus, lobortis et purus mattis, blandit dictum tellus.\n",
      "Maecenas non lorem quis tellus placerat varius. \n",
      "Nulla facilisi. \n",
      "Aenean congue fringilla justo ut aliquam. \n",
      "Mauris id ex erat. Nunc vulputate neque vitae justo facilisis, non condimentum ante sagittis. \n",
      "Morbi viverra semper lorem nec molestie. \n",
      "Maecenas tincidunt est efficitur ligula euismod, sit amet ornare est vulputate.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In non mauris justo. Duis vehicula mi vel mi pretium, a viverra erat efficitur. Cras aliquam est ac eros varius, id iaculis dui auctor. Duis pretium neque ligula, et pulvinar mi placerat et. Nulla nec nunc sit amet nunc posuere vestibulum. Ut id neque eget tortor mattis tristique. Donec ante est, blandit sit amet tristique vel, lacinia pulvinar arcu. Pellentesque scelerisque fermentum erat, id posuere justo pulvinar ut. Cras id eros sed enim aliquam lobortis. Sed lobortis nisl ut eros efficitur tincidunt. Cras justo mi, porttitor quis mattis vel, ultricies ut purus. Ut facilisis et lacus eu cursus.\n",
      "In eleifend velit vitae libero sollicitudin euismod. Fusce vitae vestibulum velit. Pellentesque vulputate lectus quis pellentesque commodo. Aliquam erat volutpat. Vestibulum in egestas velit. Pellentesque fermentum nisl vitae fringilla venenatis. Etiam id mauris vitae orci maximus ultricies. \n",
      "\n",
      "Cras fringilla ipsum magna, in fringilla dui commodo a.\n",
      "\n",
      " Namratesh sri Sumit vadhwa Axat bhar\n",
      "1 In eleifend velit vitae libero sollicitudin euismod. Lorem \n",
      "2 Cras fringilla ipsum magna, in fringilla dui commodo a. AFTER NEW LINE-1 Ipsum \n",
      "3 Aliquam erat volutpat.  AFTER NEW LINE -2 Lorem \n",
      "4 Fusce vitae vestibulum velit.  Lorem \n",
      "5 Etiam id mauris vitae orci maximus ultricies. Cras fringilla ipsum magna, in fringilla dui commodo a. Etiam vehicula luctus fermentum. In vel metus congue, pulvinar lectus vel, fermentum dui.  Ipsum \n",
      "\n",
      "Etiam vehicula luctus fermentum. In vel metus congue, pulvinar lectus vel, fermentum dui. Maecenas ante orci, egestas ut aliquet sit amet, sagittis a magna. Aliquam ante quam, pellentesque ut dignissim quis, laoreet eget est. Aliquam erat volutpat. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Ut ullamcorper justo sapien, in cursus libero viverra eget. Vivamus auctor imperdiet urna, at pulvinar leo posuere laoreet. Suspendisse neque nisl, fringilla at iaculis scelerisque, ornare vel dolor. Ut et pulvinar nunc. Pellentesque fringilla mollis efficitur. Nullam venenatis commodo imperdiet. Morbi velit neque, semper quis lorem quis, efficitur dignissim ipsum. Ut ac lorem sed turpis imperdiet eleifend sit amet id sapien.\n",
      "\n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. \n",
      "\n",
      "Nunc ac faucibus odio. Vestibulum neque massa, scelerisque sit amet ligula eu, congue molestie mi. Praesent ut varius sem. Nullam at porttitor arcu, nec lacinia nisi. Ut ac dolor vitae odio interdum condimentum. Vivamus dapibus sodales ex, vitae malesuada ipsum cursus convallis. Maecenas sed egestas nulla, ac condimentum orci. Mauris diam felis, vulputate ac suscipit et, iaculis non est. Curabitur semper arcu ac ligula semper, nec luctus nisl blandit. Integer lacinia ante ac libero lobortis imperdiet. Nullam mollis convallis ipsum, ac accumsan nunc vehicula vitae. Nulla eget justo in felis tristique fringilla. Morbi sit amet tortor quis risus auctor condimentum. Morbi in ullamcorper elit. Nulla iaculis tellus sit amet mauris tempus fringilla.\n",
      "Maecenas mauris lectus, lobortis et purus mattis, blandit dictum tellus. \n",
      "Maecenas non lorem quis tellus placerat varius. Nulla facilisi. Aenean congue fringilla justo ut aliquam. Mauris id ex erat. Nunc vulputate neque vitae justo facilisis, non condimentum ante sagittis. Morbi viverra semper lorem nec molestie. Maecenas tincidunt est efficitur ligula euismod, sit amet ornare est vulputate.\n",
      "In non mauris justo. Duis vehicula mi vel mi pretium, a viverra erat efficitur. Cras aliquam est ac eros varius, id iaculis dui auctor. Duis pretium neque ligula, et pulvinar mi placerat et. Nulla nec nunc sit amet nunc posuere vestibulum. Ut id neque eget tortor mattis tristique. Donec ante est, blandit sit amet tristique vel, lacinia pulvinar arcu. Pellentesque scelerisque fermentum erat, id posuere justo pulvinar ut. Cras id eros sed enim aliquam lobortis. Sed lobortis nisl ut eros efficitur tincidunt. Cras justo mi, porttitor quis mattis vel, ultricies ut purus. Ut facilisis et lacus eu cursus.\n",
      "In eleifend velit vitae libero sollicitudin euismod. \n",
      "Fusce vitae vestibulum velit. Pellentesque vulputate lectus quis pellentesque commodo. Aliquam erat volutpat. Vestibulum in egestas velit. Pellentesque fermentum nisl vitae fringilla venenatis. Etiam id mauris vitae orci maximus ultricies. Cras fringilla ipsum magna, in fringilla dui commodo a.\n",
      "Etiam vehicula luctus fermentum. In vel metus congue, pulvinar lectus vel, fermentum dui. Maecenas ante orci, egestas ut aliquet sit amet, sagittis a magna. Aliquam ante quam, pellentesque ut dignissim quis, laoreet eget est. Aliquam erat volutpat. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Ut ullamcorper justo sapien, in cursus libero viverra eget. Vivamus auctor imperdiet urna, at pulvinar leo posuere laoreet. Suspendisse neque nisl, fringilla at iaculis scelerisque, ornare vel dolor. Ut et pulvinar nunc. Pellentesque fringilla mollis efficitur. Nullam venenatis commodo imperdiet. Morbi velit neque, semper quis lorem quis, efficitur dignissim ipsum. Ut ac lorem sed turpis imperdiet eleifend sit amet id sapien.\n",
      "\n",
      "\n",
      "\n",
      "Maecenas mauris lectus, lobortis et purus mattis, blandit dictum tellus. \n",
      "Maecenas non lorem quis tellus placerat varius. Nulla facilisi. Aenean congue fringilla justo ut aliquam. Mauris id ex erat. Nunc vulputate neque vitae justo facilisis, non condimentum ante sagittis. Morbi viverra semper lorem nec molestie. Maecenas tincidunt est efficitur ligula euismod, sit amet ornare est vulputate.\n",
      "In non mauris justo. Duis vehicula mi vel mi pretium, a viverra erat efficitur. Cras aliquam est ac eros varius, id iaculis dui auctor. Duis pretium neque ligula, et pulvinar mi placerat et. Nulla nec nunc sit amet nunc posuere vestibulum. Ut id neque eget tortor mattis tristique. Donec ante est, blandit sit amet tristique vel, lacinia pulvinar arcu. Pellentesque scelerisque fermentum erat, id posuere justo pulvinar ut. Cras id eros sed enim aliquam lobortis. Sed lobortis nisl ut eros efficitur tincidunt. Cras justo mi, porttitor quis mattis vel, ultricies ut purus. Ut facilisis et lacus eu cursus.\n",
      "In eleifend velit vitae libero sollicitudin euismod. \n",
      "Fusce vitae vestibulum velit. Pellentesque vulputate lectus quis pellentesque commodo. Aliquam erat volutpat. Vestibulum in egestas velit. Pellentesque fermentum nisl vitae fringilla venenatis. Etiam id mauris vitae orci maximus ultricies. Cras fringilla ipsum magna, in fringilla dui commodo a.\n",
      "Etiam vehicula luctus fermentum. In vel metus congue, pulvinar lectus vel, fermentum dui. Maecenas ante orci, egestas ut aliquet sit amet, sagittis a magna. Aliquam ante quam, pellentesque ut dignissim quis, laoreet eget est. Aliquam erat volutpat. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Ut ullamcorper justo sapien, in cursus libero viverra eget. Vivamus auctor imperdiet urna, at pulvinar leo posuere laoreet. Suspendisse neque nisl, fringilla at iaculis scelerisque, ornare vel dolor. Ut et pulvinar nunc. Pellentesque fringilla mollis efficitur. Nullam venenatis commodo imperdiet. Morbi velit neque, semper quis lorem quis, efficitur dignissim ipsum. Ut ac lorem sed turpis imperdiet eleifend sit amet id sapien.\n",
      "\n",
      "Footer: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "from docx.table import Table\n",
    "from docx.text.paragraph import Paragraph\n",
    "\n",
    "\n",
    "def read_docx_objects(docx_file_path):\n",
    "    doc = Document(docx_file_path)\n",
    "    content = \"\"\n",
    "    processed_headers = set()\n",
    "    for section in doc.sections:\n",
    "        for header in section.header.paragraphs:\n",
    "            if header.text not in processed_headers:\n",
    "                content += f'Header: {header.text}\\n'\n",
    "                processed_headers.add(header.text)\n",
    "\n",
    "    content = \"\"\n",
    "    for element in list(doc.iter_inner_content()):\n",
    "        if isinstance(element, Paragraph):\n",
    "            content += f'{element.text}\\n'\n",
    "        elif isinstance(element, Table):\n",
    "            for row in element.rows:\n",
    "                row_text = ' '.join([cell.text.replace('\\n', ' ') for cell in row.cells])\n",
    "                content += f'{row_text}\\n'\n",
    "\n",
    "    processed_footers = set()\n",
    "    for section in doc.sections:\n",
    "        for footer in section.footer.paragraphs:\n",
    "            if footer.text not in processed_footers:\n",
    "                content += f'Footer: {footer.text}\\n'\n",
    "                processed_footers.add(footer.text)\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "input_docx_file_path = '/home/axat/personal/pySpark/data/file-sample_1MB_updated_inline.docx'\n",
    "\n",
    "document_content = read_docx_objects(input_docx_file_path)\n",
    "\n",
    "print(document_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum \n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc ac faucibus odio. \n",
      "\n",
      "Vestibulum neque massa, scelerisque sit amet ligula eu, congue molestie mi. Praesent ut varius sem. Nullam at porttitor arcu, nec lacinia nisi. Ut ac dolor vitae odio interdum condimentum. Vivamus dapibus sodales ex, vitae malesuada ipsum cursus convallis. Maecenas sed egestas nulla, ac condimentum orci. Mauris diam felis, vulputate ac suscipit et, iaculis non est. Curabitur semper arcu ac ligula semper, nec luctus nisl blandit. Integer lacinia ante ac libero lobortis imperdiet. Nullam mollis convallis ipsum, ac accumsan nunc vehicula vitae. Nulla eget justo in felis tristique https://chat.openai.com. Morbi sit amet tortor quis risus auctor condimentum. Morbi in ullamcorper elit. Nulla iaculis tellus sit amet mauris tempus https://chat.openai.com.\n",
      "Maecenas mauris lectus, lobortis et purus mattis, blandit dictum tellus.\n",
      "Maecenas non lorem quis tellus placerat varius. \n",
      "Nulla facilisi. \n",
      "Aenean congue https://chat.openai.com justo ut aliquam. \n",
      "Mauris id ex erat. Nunc vulputate neque vitae justo facilisis, non condimentum ante sagittis. \n",
      "Morbi viverra semper lorem nec molestie. \n",
      "Maecenas tincidunt est efficitur ligula euismod, sit amet ornare est vulputate.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In non mauris justo. Duis vehicula mi vel mi pretium, a viverra erat efficitur. Cras aliquam est ac eros varius, id iaculis dui auctor. Duis pretium neque ligula, et pulvinar mi placerat et. Nulla nec nunc sit amet nunc posuere vestibulum. Ut id neque eget tortor mattis tristique. Donec ante est, blandit sit amet tristique vel, lacinia pulvinar arcu. Pellentesque scelerisque fermentum erat, id posuere justo pulvinar ut. Cras id eros sed enim aliquam lobortis. Sed lobortis nisl ut eros efficitur tincidunt. Cras justo mi, porttitor quis mattis vel, ultricies ut purus. Ut facilisis et lacus eu cursus.\n",
      "In eleifend velit vitae libero sollicitudin euismod. Fusce vitae vestibulum velit. Pellentesque vulputate lectus quis pellentesque commodo. Aliquam erat volutpat. Vestibulum in egestas velit. Pellentesque fermentum nisl vitae https://chat.openai.com venenatis. Etiam id mauris vitae orci maximus ultricies. \n",
      "\n",
      "Cras https://chat.openai.com ipsum magna, in https://chat.openai.com dui commodo a.\n",
      "\n",
      "\n",
      "https://chat.openai.com fermentum. In vel metus congue, pulvinar lectus vel, fermentum dui. Maecenas ante orci, egestas ut aliquet sit amet, sagittis a magna. Aliquam ante quam, pellentesque ut dignissim quis, laoreet eget est. Aliquam erat volutpat. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Ut ullamcorper justo sapien, in cursus libero viverra eget. Vivamus auctor imperdiet urna, at pulvinar leo posuere laoreet. Suspendisse neque nisl, https://chat.openai.com at iaculis scelerisque, ornare vel dolor. Ut et pulvinar nunc. Pellentesque https://chat.openai.com mollis efficitur. Nullam venenatis commodo imperdiet. Morbi velit neque, semper quis lorem quis, efficitur dignissim ipsum. Ut ac lorem sed turpis imperdiet eleifend sit amet id sapien.\n",
      "\n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. \n",
      "\n",
      "Nunc ac faucibus odio. Vestibulum neque massa, scelerisque sit amet ligula eu, congue molestie mi. Praesent ut varius sem. Nullam at porttitor arcu, nec lacinia nisi. Ut ac dolor vitae odio interdum condimentum. Vivamus dapibus sodales ex, vitae malesuada ipsum cursus convallis. Maecenas sed egestas nulla, ac condimentum orci. Mauris diam felis, vulputate ac suscipit et, iaculis non est. Curabitur semper arcu ac ligula semper, nec luctus nisl blandit. Integer lacinia ante ac libero lobortis imperdiet. Nullam mollis convallis ipsum, ac accumsan nunc vehicula vitae. Nulla eget justo in felis tristique https://chat.openai.com. Morbi sit amet tortor quis risus auctor condimentum. Morbi in ullamcorper elit. Nulla iaculis tellus sit amet mauris tempus https://chat.openai.com.\n",
      "Maecenas mauris lectus, lobortis et purus mattis, blandit dictum tellus. \n",
      "Maecenas non lorem quis tellus placerat varius. Nulla facilisi. Aenean congue https://chat.openai.com justo ut aliquam. Mauris id ex erat. Nunc vulputate neque vitae justo facilisis, non condimentum ante sagittis. Morbi viverra semper lorem nec molestie. Maecenas tincidunt est efficitur ligula euismod, sit amet ornare est vulputate.\n",
      "In non mauris justo. Duis vehicula mi vel mi pretium, a viverra erat efficitur. Cras aliquam est ac eros varius, id iaculis dui auctor. Duis pretium neque ligula, et pulvinar mi placerat et. Nulla nec nunc sit amet nunc posuere vestibulum. Ut id neque eget tortor mattis tristique. Donec ante est, blandit sit amet tristique vel, lacinia pulvinar arcu. Pellentesque scelerisque fermentum erat, id posuere justo pulvinar ut. Cras id eros sed enim aliquam lobortis. Sed lobortis nisl ut eros efficitur tincidunt. Cras justo mi, porttitor quis mattis vel, ultricies ut purus. Ut facilisis et lacus eu cursus.\n",
      "In eleifend velit vitae libero sollicitudin euismod. \n",
      "Fusce vitae vestibulum velit. Pellentesque vulputate lectus quis pellentesque commodo. Aliquam erat volutpat. Vestibulum in egestas velit. Pellentesque fermentum nisl vitae https://chat.openai.com venenatis. Etiam id mauris vitae orci maximus ultricies. Cras https://chat.openai.com ipsum magna, in https://chat.openai.com dui commodo a.\n",
      "Etiam vehicula luctus fermentum. In vel metus congue, pulvinar lectus vel, fermentum dui. Maecenas ante orci, egestas ut aliquet sit amet, sagittis a magna. Aliquam ante quam, pellentesque ut dignissim quis, laoreet eget est. Aliquam erat volutpat. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Ut ullamcorper justo sapien, in cursus libero viverra eget. Vivamus auctor imperdiet urna, at pulvinar leo posuere laoreet. Suspendisse neque nisl, https://chat.openai.com at iaculis scelerisque, ornare vel dolor. Ut et pulvinar nunc. Pellentesque https://chat.openai.com mollis efficitur. Nullam venenatis commodo imperdiet. Morbi velit neque, semper quis lorem quis, efficitur dignissim ipsum. Ut ac lorem sed turpis imperdiet eleifend sit amet id sapien.\n",
      "\n",
      "\n",
      "\n",
      "Maecenas mauris lectus, lobortis et purus mattis, blandit dictum tellus. \n",
      "Maecenas non lorem quis tellus placerat varius. Nulla facilisi. Aenean congue https://chat.openai.com justo ut aliquam. Mauris id ex erat. Nunc vulputate neque vitae justo facilisis, non condimentum ante sagittis. Morbi viverra semper lorem nec molestie. Maecenas tincidunt est efficitur ligula euismod, sit amet ornare est vulputate.\n",
      "In non mauris justo. Duis vehicula mi vel mi pretium, a viverra erat efficitur. Cras aliquam est ac eros varius, id iaculis dui auctor. Duis pretium neque ligula, et pulvinar mi placerat et. Nulla nec nunc sit amet nunc posuere vestibulum. Ut id neque eget tortor mattis tristique. Donec ante est, blandit sit amet tristique vel, lacinia pulvinar arcu. Pellentesque scelerisque fermentum erat, id posuere justo pulvinar ut. Cras id eros sed enim aliquam lobortis. Sed lobortis nisl ut eros efficitur tincidunt. Cras justo mi, porttitor quis mattis vel, ultricies ut purus. Ut facilisis et lacus eu cursus.\n",
      "In eleifend velit vitae libero sollicitudin euismod. \n",
      "Fusce vitae vestibulum velit. Pellentesque vulputate lectus quis pellentesque commodo. Aliquam erat volutpat. Vestibulum in egestas velit. Pellentesque fermentum nisl vitae https://chat.openai.com venenatis. Etiam id mauris vitae orci maximus ultricies. Cras https://chat.openai.com ipsum magna, in https://chat.openai.com dui commodo a.\n",
      "Etiam vehicula luctus fermentum. In vel metus congue, pulvinar lectus vel, fermentum dui. Maecenas ante orci, egestas ut aliquet sit amet, sagittis a magna. Aliquam ante quam, pellentesque ut dignissim quis, laoreet eget est. Aliquam erat volutpat. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Ut ullamcorper justo sapien, in cursus libero viverra eget. Vivamus auctor imperdiet urna, at pulvinar leo posuere laoreet. Suspendisse neque nisl, https://chat.openai.com at iaculis scelerisque, ornare vel dolor. Ut et pulvinar nunc. Pellentesque https://chat.openai.com mollis efficitur. Nullam venenatis commodo imperdiet. Morbi velit neque, semper quis lorem quis, efficitur dignissim ipsum. Ut ac lorem sed turpis imperdiet eleifend sit amet id sapien.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to convert a DOCX file to a stream\n",
    "def docx_to_stream(docx_path):\n",
    "    with open(docx_path, 'rb') as file:\n",
    "        stream = BytesIO(file.read())\n",
    "    return stream\n",
    "\n",
    "# Function to read and print the contents of a DOCX stream\n",
    "def read_docx_from_stream(docx_stream):\n",
    "    doc = Document(docx_stream)\n",
    "    for paragraph in doc.paragraphs:\n",
    "        print(paragraph.text)\n",
    "\n",
    "# Replace 'your_document.docx' with the actual path to your DOCX file\n",
    "input_docx_file_path = '/home/axat/personal/pySpark/data/file-sample_1MB_updated_inline.docx'\n",
    "\n",
    "# Convert DOCX file to stream\n",
    "docx_stream = docx_to_stream(input_docx_file_path)\n",
    "\n",
    "# Read and print the contents of the DOCX stream\n",
    "read_docx_from_stream(docx_stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.table import Table\n",
    "from docx.text.paragraph import Paragraph\n",
    "from io import BytesIO\n",
    "\n",
    "def read_docx_objects_from_stream(docx_stream, output_file_path):\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "        doc = Document(docx_stream)\n",
    "\n",
    "        # Process headers only once\n",
    "        processed_headers = set()\n",
    "        for section in doc.sections:\n",
    "            for header in section.header.paragraphs:\n",
    "                if header.text not in processed_headers:\n",
    "                    output_file.write(f'Header: {header.text}\\n')\n",
    "                    processed_headers.add(header.text)\n",
    "\n",
    "        # Process the main content of the document\n",
    "        for element in iter_elements(doc):\n",
    "            if isinstance(element, Paragraph):\n",
    "                output_file.write(f'{element.text}\\n')  # Separate paragraphs with a new line\n",
    "            elif isinstance(element, Table):\n",
    "                for row in element.rows:\n",
    "                    row_text = ' '.join([cell.text.replace('\\n', ' ') for cell in row.cells])\n",
    "                    output_file.write(f'{row_text}\\n')  # Separate cells with a space\n",
    "\n",
    "        # Process footers only once\n",
    "        processed_footers = set()\n",
    "        for section in doc.sections:\n",
    "            for footer in section.footer.paragraphs:\n",
    "                if footer.text not in processed_footers:\n",
    "                    output_file.write(f'Footer: {footer.text}\\n')\n",
    "                    processed_footers.add(footer.text)\n",
    "\n",
    "def iter_elements(doc):\n",
    "    elements_list = []\n",
    "    for element in doc.iter_inner_content():\n",
    "        elements_list.append(element)\n",
    "\n",
    "    return elements_list\n",
    "\n",
    "# Specify the output file path\n",
    "output_file_path = '/home/axat/personal/pySpark/output/streamoutput.txt'\n",
    "\n",
    "# Replace 'your_document.docx' with the actual path to your DOCX file\n",
    "input_docx_file_path = '/home/axat/personal/pySpark/data/file-sample_1MB_updated_inline.docx'\n",
    "\n",
    "# Convert DOCX file to stream\n",
    "with open(input_docx_file_path, 'rb') as file:\n",
    "    docx_stream = BytesIO(file.read())\n",
    "\n",
    "# Use the function with the DOCX stream\n",
    "read_docx_objects_from_stream(docx_stream, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 written to /home/axat/personal/pySpark/output_1.docx\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "# file_path = '/home/axat/personal/pySpark/data/file-sample_1MB_updated_inline.docx'\n",
    "\n",
    "\n",
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    return doc\n",
    "\n",
    "def write_docx(output_path, paragraphs):\n",
    "    doc = Document()\n",
    "    for paragraph in paragraphs:\n",
    "        doc.add_paragraph(paragraph.text)\n",
    "    doc.save(output_path)\n",
    "\n",
    "def chunk_paragraphs(paragraphs, chunk_size):\n",
    "    for i in range(0, len(paragraphs), chunk_size):\n",
    "        yield paragraphs[i:i + chunk_size]\n",
    "\n",
    "def main():\n",
    "    input_file = '/home/axat/personal/pySpark/data/file-sample_1MB_updated_inline.docx'\n",
    "    output_file_prefix = '/home/axat/personal/pySpark/output'\n",
    "    chunk_size = 100\n",
    "\n",
    "    doc = read_docx(input_file)\n",
    "    all_paragraphs = doc.paragraphs\n",
    "\n",
    "    for i, chunk in enumerate(chunk_paragraphs(all_paragraphs, chunk_size), 1):\n",
    "        output_file = f'{output_file_prefix}_{i}.docx'\n",
    "        write_docx(output_file, chunk)\n",
    "        print(f'Chunk {i} written to {output_file}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.table import Table\n",
    "from docx.text.paragraph import Paragraph\n",
    "from io import BytesIO\n",
    "\n",
    "def read_docx_objects_from_stream(docx_stream, output_file_path):\n",
    "    doc = Document(docx_stream)\n",
    "    output_doc = Document()\n",
    "\n",
    "    # Process headers only once\n",
    "    processed_headers = set()\n",
    "    for section in doc.sections:\n",
    "        for header in section.header.paragraphs:\n",
    "            if header.text not in processed_headers:\n",
    "                output_doc.add_paragraph(f'Header: {header.text}')\n",
    "                processed_headers.add(header.text)\n",
    "\n",
    "    # Process the main content of the document\n",
    "    for element in iter_elements(doc):\n",
    "        if isinstance(element, Paragraph):\n",
    "            output_doc.add_paragraph(element.text)\n",
    "        elif isinstance(element, Table):\n",
    "            table = output_doc.add_table(rows=len(element.rows), cols=len(element.columns))\n",
    "            for i, row in enumerate(element.rows):\n",
    "                for j, cell in enumerate(row.cells):\n",
    "                    table.cell(i, j).text = cell.text.replace('\\n', ' ')\n",
    "\n",
    "    # Process footers only once\n",
    "    processed_footers = set()\n",
    "    for section in doc.sections:\n",
    "        for footer in section.footer.paragraphs:\n",
    "            if footer.text not in processed_footers:\n",
    "                output_doc.add_paragraph(f'Footer: {footer.text}')\n",
    "                processed_footers.add(footer.text)\n",
    "\n",
    "    output_doc.save(output_file_path)\n",
    "\n",
    "def iter_elements(doc):\n",
    "    elements_list = []\n",
    "    for element in doc.iter_inner_content():\n",
    "        elements_list.append(element)\n",
    "\n",
    "    return elements_list\n",
    "\n",
    "# Specify the output file path\n",
    "output_file_path = '/home/axat/personal/pySpark/output/streamoutput111555555551.docx'\n",
    "\n",
    "# Replace 'your_document.docx' with the actual path to your DOCX file\n",
    "input_docx_file_path = '/home/axat/personal/pySpark/data/file-sample_1MB_updated_inline.docx'\n",
    "\n",
    "# Convert DOCX file to stream\n",
    "with open(input_docx_file_path, 'rb') as file:\n",
    "    docx_stream = BytesIO(file.read())\n",
    "\n",
    "# Use the function with the DOCX stream\n",
    "read_docx_objects_from_stream(docx_stream, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/axat/personal/pySpark/doc_2_txt.ipynb Cell 9\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X13sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     docx_stream \u001b[39m=\u001b[39m BytesIO(file\u001b[39m.\u001b[39mread(chunk_size))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X13sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m \u001b[39m# Use the function with the DOCX stream\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X13sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m read_docx_objects_from_stream(docx_stream, output_file_path)\n",
      "\u001b[1;32m/home/axat/personal/pySpark/doc_2_txt.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X13sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_docx_objects_from_stream\u001b[39m(docx_stream, output_file_path):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X13sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     doc \u001b[39m=\u001b[39m Document(docx_stream)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X13sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m# output_doc = Document()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X13sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X13sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39m# # Process headers only once\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X13sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     \u001b[39m#             new_footer.add_run(f'Footer: {footer.text}')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X13sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     \u001b[39m#             processed_footers.add(footer.text)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X13sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     doc\u001b[39m.\u001b[39msave(output_file_path)\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/docx/api.py:23\u001b[0m, in \u001b[0;36mDocument\u001b[0;34m(docx)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return a |Document| object loaded from `docx`, where `docx` can be either a path\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mto a ``.docx`` file (a string) or a file-like object.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[39mIf `docx` is missing or ``None``, the built-in default document \"template\" is\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mloaded.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m docx \u001b[39m=\u001b[39m _default_docx_path() \u001b[39mif\u001b[39;00m docx \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m docx\n\u001b[0;32m---> 23\u001b[0m document_part \u001b[39m=\u001b[39m Package\u001b[39m.\u001b[39;49mopen(docx)\u001b[39m.\u001b[39mmain_document_part\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m document_part\u001b[39m.\u001b[39mcontent_type \u001b[39m!=\u001b[39m CT\u001b[39m.\u001b[39mWML_DOCUMENT_MAIN:\n\u001b[1;32m     25\u001b[0m     tmpl \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is not a Word file, content type is \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/docx/opc/package.py:116\u001b[0m, in \u001b[0;36mOpcPackage.open\u001b[0;34m(cls, pkg_file)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mcls\u001b[39m, pkg_file):\n\u001b[1;32m    115\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return an |OpcPackage| instance loaded with the contents of `pkg_file`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     pkg_reader \u001b[39m=\u001b[39m PackageReader\u001b[39m.\u001b[39;49mfrom_file(pkg_file)\n\u001b[1;32m    117\u001b[0m     package \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m()\n\u001b[1;32m    118\u001b[0m     Unmarshaller\u001b[39m.\u001b[39munmarshal(pkg_reader, package, PartFactory)\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/docx/opc/pkgreader.py:22\u001b[0m, in \u001b[0;36mPackageReader.from_file\u001b[0;34m(pkg_file)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_file\u001b[39m(pkg_file):\n\u001b[1;32m     21\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a |PackageReader| instance loaded with contents of `pkg_file`.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     phys_reader \u001b[39m=\u001b[39m PhysPkgReader(pkg_file)\n\u001b[1;32m     23\u001b[0m     content_types \u001b[39m=\u001b[39m _ContentTypeMap\u001b[39m.\u001b[39mfrom_xml(phys_reader\u001b[39m.\u001b[39mcontent_types_xml)\n\u001b[1;32m     24\u001b[0m     pkg_srels \u001b[39m=\u001b[39m PackageReader\u001b[39m.\u001b[39m_srels_for(phys_reader, PACKAGE_URI)\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/docx/opc/phys_pkg.py:76\u001b[0m, in \u001b[0;36m_ZipPkgReader.__init__\u001b[0;34m(self, pkg_file)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, pkg_file):\n\u001b[1;32m     75\u001b[0m     \u001b[39msuper\u001b[39m(_ZipPkgReader, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_zipf \u001b[39m=\u001b[39m ZipFile(pkg_file, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/lib/python3.11/zipfile.py:1302\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1301\u001b[0m     \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m-> 1302\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_RealGetContents()\n\u001b[1;32m   1303\u001b[0m     \u001b[39melif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   1304\u001b[0m         \u001b[39m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m         \u001b[39m# even if no files are added to the archive\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_didModify \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/zipfile.py:1369\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[39mraise\u001b[39;00m BadZipFile(\u001b[39m\"\u001b[39m\u001b[39mFile is not a zip file\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1368\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m endrec:\n\u001b[0;32m-> 1369\u001b[0m     \u001b[39mraise\u001b[39;00m BadZipFile(\u001b[39m\"\u001b[39m\u001b[39mFile is not a zip file\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1371\u001b[0m     \u001b[39mprint\u001b[39m(endrec)\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "from io import BytesIO\n",
    "\n",
    "def copy_paragraph_format(src_paragraph, dest_paragraph):\n",
    "    dest_paragraph.style = src_paragraph.style\n",
    "    dest_paragraph.alignment = src_paragraph.alignment\n",
    "\n",
    "def copy_run_format(src_run, dest_run):\n",
    "    dest_run.bold = src_run.bold\n",
    "    dest_run.italic = src_run.italic\n",
    "    dest_run.underline = src_run.underline\n",
    "    dest_run.font.name = src_run.font.name\n",
    "    dest_run.font.size = src_run.font.size\n",
    "    dest_run.font.color.rgb = src_run.font.color.rgb\n",
    "\n",
    "def copy_table_format(src_table, dest_table):\n",
    "    dest_table.style = src_table.style\n",
    "    for row in dest_table.rows:\n",
    "        for cell in row.cells:\n",
    "            cell.paragraphs[0].style = src_table.cell(0, 0).paragraphs[0].style\n",
    "\n",
    "def copy_table_contents(src_table, dest_table):\n",
    "    for i, src_row in enumerate(src_table.rows):\n",
    "        dest_row = dest_table.row_cells(i)\n",
    "        for j, src_cell in enumerate(src_row.cells):\n",
    "            dest_paragraph = dest_row[j].paragraphs[0]\n",
    "            for src_paragraph in src_cell.paragraphs:\n",
    "                new_paragraph = dest_table.cell(i, j).add_paragraph()\n",
    "                copy_paragraph_format(src_paragraph, new_paragraph)\n",
    "                for src_run in src_paragraph.runs:\n",
    "                    new_run = new_paragraph.add_run(src_run.text)\n",
    "                    copy_run_format(src_run, new_run)\n",
    "\n",
    "def read_docx_objects_from_stream(docx_stream, output_file_path):\n",
    "    doc = Document(docx_stream)\n",
    "    # output_doc = Document()\n",
    "\n",
    "    # # Process headers only once\n",
    "    # processed_headers = set()\n",
    "    # for section in doc.sections:\n",
    "    #     for header in section.header.paragraphs:\n",
    "    #         if header.text not in processed_headers:\n",
    "    #             new_header = output_doc.add_paragraph()\n",
    "    #             copy_paragraph_format(header, new_header)\n",
    "    #             new_header.add_run(f'Header: {header.text}')\n",
    "    #             processed_headers.add(header.text)\n",
    "\n",
    "    # # Process the main content of the document\n",
    "    # for element in iter_elements(doc):\n",
    "    #     if isinstance(element, Paragraph):\n",
    "    #         new_paragraph = output_doc.add_paragraph()\n",
    "    #         copy_paragraph_format(element, new_paragraph)\n",
    "    #         new_paragraph.add_run(element.text)\n",
    "    #     elif isinstance(element, Table):\n",
    "    #         new_table = output_doc.add_table(rows=len(element.rows), cols=len(element.columns))\n",
    "    #         copy_table_format(element, new_table)\n",
    "    #         copy_table_contents(element, new_table)\n",
    "\n",
    "    # # Process footers only once\n",
    "    # processed_footers = set()\n",
    "    # for section in doc.sections:\n",
    "    #     for footer in section.footer.paragraphs:\n",
    "    #         if footer.text not in processed_footers:\n",
    "    #             new_footer = output_doc.add_paragraph()\n",
    "    #             copy_paragraph_format(footer, new_footer)\n",
    "    #             new_footer.add_run(f'Footer: {footer.text}')\n",
    "    #             processed_footers.add(footer.text)\n",
    "\n",
    "    doc.save(output_file_path)\n",
    "\n",
    "def iter_elements(doc):\n",
    "    elements_list = []\n",
    "    for element in doc.iter_inner_content():\n",
    "        elements_list.append(element)\n",
    "\n",
    "    return elements_list\n",
    "\n",
    "# Specify the output file path\n",
    "output_file_path = '/home/axat/personal/pySpark/output/streamoutput_with_format.docx'\n",
    "\n",
    "# Replace 'your_document.docx' with the actual path to your DOCX file\n",
    "input_docx_file_path = '/home/axat/personal/pySpark/data/file-sample_1MB_updated_inline.docx'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert DOCX file to stream\n",
    "with open(input_docx_file_path, 'rb') as file:\n",
    "    file_size = file.seek(0, 2)  # Get the file size\n",
    "    file.seek(0)  # Reset the file pointer to the beginning\n",
    "    chunk_size = file_size // 2\n",
    "    docx_stream = BytesIO(file.read(chunk_size))\n",
    "\n",
    "\n",
    "\n",
    "# Use the function with the DOCX stream\n",
    "read_docx_objects_from_stream(docx_stream, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "PackageNotFoundError",
     "evalue": "Package not found at '/home/axat/personal/pySpark/chunk1.docx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/axat/personal/pySpark/doc_2_txt.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Use the function to read the file into two equal-sized chunks and save them\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X14sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m read_file_in_two_chunks_and_save(input_docx_file_path, output_file_path1, output_file_path2)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X14sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m doc \u001b[39m=\u001b[39m Document(\u001b[39m'\u001b[39;49m\u001b[39m/home/axat/personal/pySpark/chunk1.docx\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X14sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mprint\u001b[39m(doc\u001b[39m.\u001b[39mparagraphs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext)\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/docx/api.py:23\u001b[0m, in \u001b[0;36mDocument\u001b[0;34m(docx)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return a |Document| object loaded from `docx`, where `docx` can be either a path\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mto a ``.docx`` file (a string) or a file-like object.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[39mIf `docx` is missing or ``None``, the built-in default document \"template\" is\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mloaded.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m docx \u001b[39m=\u001b[39m _default_docx_path() \u001b[39mif\u001b[39;00m docx \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m docx\n\u001b[0;32m---> 23\u001b[0m document_part \u001b[39m=\u001b[39m Package\u001b[39m.\u001b[39;49mopen(docx)\u001b[39m.\u001b[39mmain_document_part\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m document_part\u001b[39m.\u001b[39mcontent_type \u001b[39m!=\u001b[39m CT\u001b[39m.\u001b[39mWML_DOCUMENT_MAIN:\n\u001b[1;32m     25\u001b[0m     tmpl \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is not a Word file, content type is \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/docx/opc/package.py:116\u001b[0m, in \u001b[0;36mOpcPackage.open\u001b[0;34m(cls, pkg_file)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mcls\u001b[39m, pkg_file):\n\u001b[1;32m    115\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return an |OpcPackage| instance loaded with the contents of `pkg_file`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     pkg_reader \u001b[39m=\u001b[39m PackageReader\u001b[39m.\u001b[39;49mfrom_file(pkg_file)\n\u001b[1;32m    117\u001b[0m     package \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m()\n\u001b[1;32m    118\u001b[0m     Unmarshaller\u001b[39m.\u001b[39munmarshal(pkg_reader, package, PartFactory)\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/docx/opc/pkgreader.py:22\u001b[0m, in \u001b[0;36mPackageReader.from_file\u001b[0;34m(pkg_file)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_file\u001b[39m(pkg_file):\n\u001b[1;32m     21\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a |PackageReader| instance loaded with contents of `pkg_file`.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     phys_reader \u001b[39m=\u001b[39m PhysPkgReader(pkg_file)\n\u001b[1;32m     23\u001b[0m     content_types \u001b[39m=\u001b[39m _ContentTypeMap\u001b[39m.\u001b[39mfrom_xml(phys_reader\u001b[39m.\u001b[39mcontent_types_xml)\n\u001b[1;32m     24\u001b[0m     pkg_srels \u001b[39m=\u001b[39m PackageReader\u001b[39m.\u001b[39m_srels_for(phys_reader, PACKAGE_URI)\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/docx/opc/phys_pkg.py:21\u001b[0m, in \u001b[0;36mPhysPkgReader.__new__\u001b[0;34m(cls, pkg_file)\u001b[0m\n\u001b[1;32m     19\u001b[0m         reader_cls \u001b[39m=\u001b[39m _ZipPkgReader\n\u001b[1;32m     20\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m         \u001b[39mraise\u001b[39;00m PackageNotFoundError(\u001b[39m\"\u001b[39m\u001b[39mPackage not found at \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m pkg_file)\n\u001b[1;32m     22\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# assume it's a stream and pass it to Zip reader to sort out\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     reader_cls \u001b[39m=\u001b[39m _ZipPkgReader\n",
      "\u001b[0;31mPackageNotFoundError\u001b[0m: Package not found at '/home/axat/personal/pySpark/chunk1.docx'"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "from docx import Document\n",
    "\n",
    "def save_chunk_to_docx(chunk, output_file_path):\n",
    "    with open(output_file_path, 'wb') as output_file:\n",
    "        output_file.write(chunk.getvalue())\n",
    "\n",
    "def read_file_in_two_chunks_and_save(file_path, output_file_path1, output_file_path2):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        file_size = file.seek(0, 2)  # Get the file size\n",
    "        file.seek(0)  # Reset the file pointer to the beginning\n",
    "\n",
    "        chunk_size = file_size // 2\n",
    "\n",
    "        # Read the first half\n",
    "        chunk1 = BytesIO(file.read(chunk_size))\n",
    "\n",
    "        # Read the second half\n",
    "        chunk2 = BytesIO(file.read(chunk_size))\n",
    "\n",
    "    # Save the chunks into different DOCX files\n",
    "    save_chunk_to_docx(chunk1, output_file_path1)\n",
    "    save_chunk_to_docx(chunk2, output_file_path2)\n",
    "\n",
    "# Replace 'your_document.docx' with the actual path to your DOCX file\n",
    "input_docx_file_path = '/home/axat/personal/pySpark/data/file-sample_1MB_updated_inline.docx'\n",
    "\n",
    "# Specify the output file paths for the two chunks\n",
    "output_file_path1 = 'chunk1.docx'\n",
    "output_file_path2 = 'chunk2.docx'\n",
    "\n",
    "# Use the function to read the file into two equal-sized chunks and save them\n",
    "read_file_in_two_chunks_and_save(input_docx_file_path, output_file_path1, output_file_path2)\n",
    "\n",
    "doc = Document('/home/axat/personal/pySpark/chunk1.docx')\n",
    "print(doc.paragraphs[0].text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xce in position 17: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/home/axat/personal/pySpark/doc_2_txt.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X15sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m output_file_path2 \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mchunk2.docx\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X15sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Use the function to read the file into two equal-sized chunks, print them, and save them\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X15sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m read_file_in_two_chunks_and_save(input_docx_file_path, output_file_path1, output_file_path2)\n",
      "\u001b[1;32m/home/axat/personal/pySpark/doc_2_txt.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m chunk1 \u001b[39m=\u001b[39m BytesIO(file\u001b[39m.\u001b[39mread(chunk_size))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mChunk 1:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(chunk1\u001b[39m.\u001b[39;49mgetvalue()\u001b[39m.\u001b[39;49mdecode(\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m30\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/axat/personal/pySpark/doc_2_txt.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Read the second half\u001b[39;00m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xce in position 17: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "from docx import Document\n",
    "\n",
    "def save_chunk_to_docx(chunk, output_file_path):\n",
    "    with open(output_file_path, 'wb') as output_file:\n",
    "        output_file.write(chunk.getvalue())\n",
    "\n",
    "def read_file_in_two_chunks_and_save(file_path, output_file_path1, output_file_path2):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        file_size = file.seek(0, 2)  # Get the file size\n",
    "        file.seek(0)  # Reset the file pointer to the beginning\n",
    "\n",
    "        chunk_size = file_size // 2\n",
    "\n",
    "        # Read the first half\n",
    "        chunk1 = BytesIO(file.read(chunk_size))\n",
    "        print(\"Chunk 1:\")\n",
    "        print(chunk1.getvalue().decode('utf-8'))\n",
    "        print(\"=\" * 30)\n",
    "\n",
    "        # Read the second half\n",
    "        chunk2 = BytesIO(file.read(chunk_size))\n",
    "        print(\"Chunk 2:\")\n",
    "        print(chunk2.getvalue().decode('utf-8'))\n",
    "        print(\"=\" * 30)\n",
    "\n",
    "    # Save the chunks into different DOCX files\n",
    "    save_chunk_to_docx(chunk1, output_file_path1)\n",
    "    save_chunk_to_docx(chunk2, output_file_path2)\n",
    "\n",
    "# Replace 'your_document.docx' with the actual path to your DOCX file\n",
    "input_docx_file_path = '/home/axat/personal/pySpark/data/file-sample_1MB_updated_inline.docx'\n",
    "\n",
    "# Specify the output file paths for the two chunks\n",
    "output_file_path1 = 'chunk1.docx'\n",
    "output_file_path2 = 'chunk2.docx'\n",
    "\n",
    "# Use the function to read the file into two equal-sized chunks, print them, and save them\n",
    "read_file_in_two_chunks_and_save(input_docx_file_path, output_file_path1, output_file_path2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from io import BytesIO\n",
    "\n",
    "def replace_text_in_docx(doc, target_text, replacement_text):\n",
    "    for paragraph in doc.paragraphs:\n",
    "        if target_text in paragraph.text:\n",
    "            paragraph.text = paragraph.text.replace(target_text, replacement_text)\n",
    "\n",
    "    for table in doc.tables:\n",
    "        for row in table.rows:\n",
    "            for cell in row.cells:\n",
    "                if target_text in cell.text:\n",
    "                    cell.text = cell.text.replace(target_text, replacement_text)\n",
    "\n",
    "# Replace 'your_document.docx' with the actual path to your DOCX file\n",
    "input_docx_file_path = '/home/axat/personal/pySpark/data/file-sample_1MB_updated_inline.docx'\n",
    "\n",
    "# Open the existing DOCX file\n",
    "with open(input_docx_file_path, 'rb') as file:\n",
    "    docx_stream = BytesIO(file.read())\n",
    "    doc = Document(docx_stream)\n",
    "\n",
    "# Specify the text to be replaced and the replacement text\n",
    "target_text = 'Lorem'\n",
    "replacement_text = 'sumit'\n",
    "\n",
    "# Use the function to replace the text in the original DOCX document\n",
    "replace_text_in_docx(doc, target_text, replacement_text)\n",
    "\n",
    "# Save the changes to the existing file\n",
    "doc.save(input_docx_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
