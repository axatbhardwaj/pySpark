{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrlbh3BcFLHn",
        "outputId": "2e9e221c-961c-4ace-a3c6-7e67b7b5a240"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=24cc0d2a7e357959b6e65d3acb57186e17133ea8398b63280a78c7c00a2e5ae5\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oW2cn5V_nJmW"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "g8K2vNMVns_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "422dff39-3074-4e11-da89-114ba083b2e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-20 09:01:03--  https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 388341449 (370M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.4.1-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.4.1-bin-had 100%[===================>] 370.35M  20.9MB/s    in 22s     \n",
            "\n",
            "2023-12-20 09:01:25 (16.9 MB/s) - ‘spark-3.4.1-bin-hadoop3.tgz’ saved [388341449/388341449]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf spark-3.4.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "kRxllwjvnucl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "jXpfwISypFX2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget  https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar"
      ],
      "metadata": {
        "id": "T5AsubjKwHX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b14a7f1a-f35d-4c15-ff16-ed47f67a5a56"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-20 09:01:37--  https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 199.232.192.209, 199.232.196.209, 2a04:4e42:4c::209, ...\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|199.232.192.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 962685 (940K) [application/java-archive]\n",
            "Saving to: ‘hadoop-aws-3.3.4.jar’\n",
            "\n",
            "\rhadoop-aws-3.3.4.ja   0%[                    ]       0  --.-KB/s               \rhadoop-aws-3.3.4.ja 100%[===================>] 940.12K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-12-20 09:01:37 (19.2 MB/s) - ‘hadoop-aws-3.3.4.jar’ saved [962685/962685]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget  https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.595/aws-java-sdk-bundle-1.12.595.jar"
      ],
      "metadata": {
        "id": "dvg1SYzqzoqb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3db7ad8-7390-49a1-94e9-fb32e546edfa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-20 09:01:38--  https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.595/aws-java-sdk-bundle-1.12.595.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 199.232.192.209, 199.232.196.209, 2a04:4e42:4c::209, ...\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|199.232.192.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 354662360 (338M) [application/java-archive]\n",
            "Saving to: ‘aws-java-sdk-bundle-1.12.595.jar’\n",
            "\n",
            "aws-java-sdk-bundle 100%[===================>] 338.23M   200MB/s    in 1.7s    \n",
            "\n",
            "2023-12-20 09:01:40 (200 MB/s) - ‘aws-java-sdk-bundle-1.12.595.jar’ saved [354662360/354662360]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DF3SmxeJwXH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv aws-java-sdk-bundle-1.12.595.jar /content/spark-3.4.1-bin-hadoop3/jars/"
      ],
      "metadata": {
        "id": "NTapUn36zs9V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv hadoop-aws-3.3.4.jar /content/spark-3.4.1-bin-hadoop3/jars/"
      ],
      "metadata": {
        "id": "yd2mPnJtwX-J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hadoop-aws-3.3.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIvsgcs-I4tT",
        "outputId": "65539feb-32ea-463a-ad99-99c697932e64"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement hadoop-aws-3.3.5 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for hadoop-aws-3.3.5\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkConf\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\"\n",
        "\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk\" #change this accordingly\n",
        "# os.environ[\"SPARK_HOME\"] = \"/home/axat/personal/pySpark/s3-connection/spark-3.4.1-bin-hadoop3\" #chnage this accordingly\n",
        "\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] =  \"AKIA6GL5OZOXYIJNYQ4Y\"\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"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\"\n",
        "\n",
        "# Specify the Hadoop and AWS configurations\n",
        "conf = SparkConf()\n",
        "conf.set(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.5,com.amazonaws:aws-java-sdk-bundle:1.12.595\")\n",
        "conf.set(\"spark.hadoop.fs.s3a.endpoint\", \"s3.amazonaws.com\")\n",
        "conf.set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
        "\n",
        "# Read CSV from S3\n",
        "df = spark.read.csv('s3a://deepak-test-infrablok/tested.csv', inferSchema=True)\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnKONPMWqKOc",
        "outputId": "b109a6f2-7742-417d-96b0-23233f486e73"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|        _c0|     _c1|   _c2|                 _c3|   _c4| _c5|  _c6|  _c7|             _c8|    _c9| _c10|    _c11|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "|        892|       0|     3|    Kelly, Mr. James|  male|34.5|    0|    0|          330911| 7.8292| null|       Q|\n",
            "|        893|       1|     3|Wilkes, Mrs. Jame...|female|  47|    1|    0|          363272|      7| null|       S|\n",
            "|        894|       0|     2|Myles, Mr. Thomas...|  male|  62|    0|    0|          240276| 9.6875| null|       Q|\n",
            "|        895|       0|     3|    Wirz, Mr. Albert|  male|  27|    0|    0|          315154| 8.6625| null|       S|\n",
            "|        896|       1|     3|Hirvonen, Mrs. Al...|female|  22|    1|    1|         3101298|12.2875| null|       S|\n",
            "|        897|       0|     3|Svensson, Mr. Joh...|  male|  14|    0|    0|            7538|  9.225| null|       S|\n",
            "|        898|       1|     3|Connolly, Miss. Kate|female|  30|    0|    0|          330972| 7.6292| null|       Q|\n",
            "|        899|       0|     2|Caldwell, Mr. Alb...|  male|  26|    1|    1|          248738|     29| null|       S|\n",
            "|        900|       1|     3|Abrahim, Mrs. Jos...|female|  18|    0|    0|            2657| 7.2292| null|       C|\n",
            "|        901|       0|     3|Davies, Mr. John ...|  male|  21|    2|    0|       A/4 48871|  24.15| null|       S|\n",
            "|        902|       0|     3|    Ilieff, Mr. Ylio|  male|null|    0|    0|          349220| 7.8958| null|       S|\n",
            "|        903|       0|     1|Jones, Mr. Charle...|  male|  46|    0|    0|             694|     26| null|       S|\n",
            "|        904|       1|     1|Snyder, Mrs. John...|female|  23|    1|    0|           21228|82.2667|  B45|       S|\n",
            "|        905|       0|     2|Howard, Mr. Benjamin|  male|  63|    1|    0|           24065|     26| null|       S|\n",
            "|        906|       1|     1|Chaffee, Mrs. Her...|female|  47|    1|    0|     W.E.P. 5734| 61.175|  E31|       S|\n",
            "|        907|       1|     2|del Carlo, Mrs. S...|female|  24|    1|    0|   SC/PARIS 2167|27.7208| null|       C|\n",
            "|        908|       0|     2|   Keane, Mr. Daniel|  male|  35|    0|    0|          233734|  12.35| null|       Q|\n",
            "|        909|       0|     3|   Assaf, Mr. Gerios|  male|  21|    0|    0|            2692|  7.225| null|       C|\n",
            "|        910|       1|     3|Ilmakangas, Miss....|female|  27|    1|    0|STON/O2. 3101270|  7.925| null|       S|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "bY_nRoA3oLni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51112d66-7602-425e-ef7f-f4a14d81b2b9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  spark-3.4.1-bin-hadoop3  spark-3.4.1-bin-hadoop3.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "Q8r6LPCN0QEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebaccce9-ee6a-45a0-f8f1-f66b792e2138"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    }
  ]
}