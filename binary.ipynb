{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "\n",
    "# Convert image to binary data\n",
    "def image_to_binary(image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        binary_data = image_file.read()\n",
    "    return binary_data\n",
    "\n",
    "# Save binary data to a file\n",
    "def save_binary_data(binary_data, output_path):\n",
    "    output_directory = os.path.dirname(output_path)\n",
    "    \n",
    "    # Check if the output directory exists; if not, create it\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    with open(output_path, 'wb') as file:\n",
    "        file.write(binary_data)\n",
    "\n",
    "# Reconstruct image from binary data\n",
    "def reconstruct_image(binary_data, output_path):\n",
    "    image = Image.open(io.BytesIO(binary_data))\n",
    "    image.save(output_path)\n",
    "\n",
    "# Specify the image file path\n",
    "image_path = \"/home/axat/personal/pySpark/data/Screenshot_20231122_151744.png\"\n",
    "\n",
    "# Convert image to binary data\n",
    "binary_data = image_to_binary(image_path)\n",
    "\n",
    "# Save binary data to a file\n",
    "binary_file_path = \"/home/axat/personal/pySpark/output/image_binary.bin\"\n",
    "save_binary_data(binary_data, binary_file_path)\n",
    "\n",
    "# Reconstruct image from binary file\n",
    "reconstructed_image_path = \"/home/axat/personal/pySpark/output/reconstructed_image.png\"\n",
    "reconstruct_image(binary_data, reconstructed_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- content: binary (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+--------------------+\n",
      "|                path|    modificationTime| length|             content|\n",
      "+--------------------+--------------------+-------+--------------------+\n",
      "|file:/home/axat/p...|2023-11-22 15:17:...|2215342|[89 50 4E 47 0D 0...|\n",
      "+--------------------+--------------------+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, BinaryType\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ImageBinaryProcessing\").getOrCreate()\n",
    "\n",
    "# Specify the image file path\n",
    "image_path = \"/home/axat/personal/pySpark/data/Screenshot_20231122_151744.png\"\n",
    "\n",
    "# Define the schema for the DataFrame\n",
    "schema = StructType([StructField(\"FileName\", StringType(), True),\n",
    "                     StructField(\"ImageData\", BinaryType(), True)])\n",
    "\n",
    "# Use the binaryFiles function to read binary data directly into a DataFrame\n",
    "image_df = spark.read.format(\"binaryFile\").option(\"pathGlobFilter\", \"*.png\").load(image_path)\n",
    "\n",
    "# Show the DataFrame\n",
    "# image_df.schema()\n",
    "image_df.printSchema()\n",
    "# image_df\n",
    "image_df.show()\n",
    "\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, BinaryType\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ImageBinaryProcessing\").getOrCreate()\n",
    "\n",
    "# Specify the image file path\n",
    "image_path = \"/home/axat/personal/pySpark/data/Screenshot_20231122_151744.png\"\n",
    "\n",
    "# Define the schema for the DataFrame\n",
    "schema = StructType([StructField(\"FileName\", StringType(), True),\n",
    "                     StructField(\"ImageData\", BinaryType(), True)])\n",
    "\n",
    "# Use the binaryFiles function to read binary data directly into a DataFrame\n",
    "image_df = spark.read.format(\"binaryFile\") \\\n",
    "    .option(\"pathGlobFilter\", \"*.png\") \\\n",
    "    .load(image_path) \\\n",
    "    .withColumnRenamed(\"path\", \"FileName\") \\\n",
    "    .select(\"FileName\", \"content\")\n",
    "\n",
    "# Show the DataFrame\n",
    "image_df.show(truncate=False)\n",
    "\n",
    "# Convert hexadecimal string to binary data\n",
    "def hex_to_binary(hex_string):\n",
    "    return bytes.fromhex(hex_string)\n",
    "\n",
    "# Decode base64-encoded binary data and reconstruct the original image\n",
    "def reconstruct_image(row):\n",
    "    file_name = row[\"FileName\"]\n",
    "    hex_data = row[\"content\"]\n",
    "    binary_data = hex_to_binary(hex_data)\n",
    "    output_path = f\"/home/axat/personal/pySpark/output/reconstructed_{file_name}\"\n",
    "\n",
    "    with open(output_path, \"wb\") as file:\n",
    "        file.write(binary_data)\n",
    "\n",
    "# Use map transformation instead of foreach\n",
    "reconstructed_images_df = image_df.rdd.map(reconstruct_image).toDF()\n",
    "\n",
    "# Write the reconstructed images to the output directory\n",
    "reconstructed_images_df.write.mode(\"overwrite\").parquet(\"/home/axat/personal/pySpark/output/reconstructed_images\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
