{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oW2cn5V_nJmW"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g8K2vNMVns_W"
      },
      "outputs": [],
      "source": [
        "!wget -q https://dlcdn.apache.org/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kRxllwjvnucl"
      },
      "outputs": [],
      "source": [
        "!tar xf spark-3.4.1-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jXpfwISypFX2"
      },
      "outputs": [],
      "source": [
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DXzEeL74pUcE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ToPWNLKFptMm"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qahSS34qp8Qh",
        "outputId": "063eb636-9352-48f1-965c-de4d77e9729f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/spark-3.4.1-bin-hadoop3'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "findspark.find()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "T5AsubjKwHX_"
      },
      "outputs": [],
      "source": [
        "!wget -q https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.5/hadoop-aws-3.3.5.jar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dvg1SYzqzoqb"
      },
      "outputs": [],
      "source": [
        "!wget -q https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.595/aws-java-sdk-bundle-1.12.595.jar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF3SmxeJwXH1"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NTapUn36zs9V"
      },
      "outputs": [],
      "source": [
        "!mv aws-java-sdk-bundle-1.12.595.jar /content/spark-3.4.1-bin-hadoop3/jars/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yd2mPnJtwX-J"
      },
      "outputs": [],
      "source": [
        "!mv hadoop-aws-3.3.4.jar /content/spark-3.4.1-bin-hadoop3/jars/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "m3ewRGQxPIkg"
      },
      "outputs": [],
      "source": [
        "! export AWS_ACCESS_KEY_ID=\n",
        "! export AWS_SECRET_ACCESS_KEY="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnKONPMWqKOc",
        "outputId": "f1c3cbfb-6c68-4bfe-8d27-f48acc926d7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|        _c0|     _c1|   _c2|                 _c3|   _c4| _c5|  _c6|  _c7|             _c8|    _c9| _c10|    _c11|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "|        892|       0|     3|    Kelly, Mr. James|  male|34.5|    0|    0|          330911| 7.8292| null|       Q|\n",
            "|        893|       1|     3|Wilkes, Mrs. Jame...|female|  47|    1|    0|          363272|      7| null|       S|\n",
            "|        894|       0|     2|Myles, Mr. Thomas...|  male|  62|    0|    0|          240276| 9.6875| null|       Q|\n",
            "|        895|       0|     3|    Wirz, Mr. Albert|  male|  27|    0|    0|          315154| 8.6625| null|       S|\n",
            "|        896|       1|     3|Hirvonen, Mrs. Al...|female|  22|    1|    1|         3101298|12.2875| null|       S|\n",
            "|        897|       0|     3|Svensson, Mr. Joh...|  male|  14|    0|    0|            7538|  9.225| null|       S|\n",
            "|        898|       1|     3|Connolly, Miss. Kate|female|  30|    0|    0|          330972| 7.6292| null|       Q|\n",
            "|        899|       0|     2|Caldwell, Mr. Alb...|  male|  26|    1|    1|          248738|     29| null|       S|\n",
            "|        900|       1|     3|Abrahim, Mrs. Jos...|female|  18|    0|    0|            2657| 7.2292| null|       C|\n",
            "|        901|       0|     3|Davies, Mr. John ...|  male|  21|    2|    0|       A/4 48871|  24.15| null|       S|\n",
            "|        902|       0|     3|    Ilieff, Mr. Ylio|  male|null|    0|    0|          349220| 7.8958| null|       S|\n",
            "|        903|       0|     1|Jones, Mr. Charle...|  male|  46|    0|    0|             694|     26| null|       S|\n",
            "|        904|       1|     1|Snyder, Mrs. John...|female|  23|    1|    0|           21228|82.2667|  B45|       S|\n",
            "|        905|       0|     2|Howard, Mr. Benjamin|  male|  63|    1|    0|           24065|     26| null|       S|\n",
            "|        906|       1|     1|Chaffee, Mrs. Her...|female|  47|    1|    0|     W.E.P. 5734| 61.175|  E31|       S|\n",
            "|        907|       1|     2|del Carlo, Mrs. S...|female|  24|    1|    0|   SC/PARIS 2167|27.7208| null|       C|\n",
            "|        908|       0|     2|   Keane, Mr. Daniel|  male|  35|    0|    0|          233734|  12.35| null|       Q|\n",
            "|        909|       0|     3|   Assaf, Mr. Gerios|  male|  21|    0|    0|            2692|  7.225| null|       C|\n",
            "|        910|       1|     3|Ilmakangas, Miss....|female|  27|    1|    0|STON/O2. 3101270|  7.925| null|       S|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\"\n",
        "\n",
        "from pyspark import SparkConf\n",
        "\n",
        "# Specify the Hadoop and AWS configurations\n",
        "conf = SparkConf()\n",
        "# Specify the Hadoop and AWS configurations\n",
        "conf = SparkConf()\n",
        "conf.set(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.5,com.amazonaws:aws-java-sdk-bundle:1.12.595\")\n",
        "conf.set(\"spark.hadoop.fs.s3a.access.key\", \"YOUR_ACCESS_KEY_ID\")\n",
        "conf.set(\"spark.hadoop.fs.s3a.secret.key\", \"YOUR_SECRET_ACCESS_KEY\")\n",
        "conf.set(\"spark.hadoop.fs.s3a.endpoint\", \"s3.amazonaws.com\")\n",
        "conf.set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
        "\n",
        "# Read CSV from S3\n",
        "df = spark.read.csv('s3a://deepak-test-infrablok/tested.csv', inferSchema=True)\n",
        "df.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Rest of your code\n",
        "# df = spark.read.csv('s3a://deepak-test-infrablok.s3.amazonaws.com/tested.csv', inferSchema=True)\n",
        "# df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY_nRoA3oLni"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8r6LPCN0QEL"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
